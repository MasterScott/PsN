\input{inputs/format_header.tex}
\guidetitle{SIR user guide}{2015-08-07}
\usepackage{amsmath}

\begin{document}

\maketitle

\newcommand{\guidetoolname}{sir}

\section{Introduction}
The sir program calculates uncertainty
on model parameters for the input model using the Sampling Importance Resampling (SIR) procedure.
The SIR procedure is described in\\
\emph{Application of Sampling Importance Resampling to estimate parameter uncertainty distributions}, 
PAGE 22 (2013) Abstr 2907, Dosne AG, Bergstrand M, Karlsson MO.\\
and in\\
\emph{Determination of Appropriate Settings in the Assessment of Parameter Uncertainty Distributions 
using Sampling Importance Resampling (SIR)}, 
PAGE 24 (2015) Abstr 3546, Dosne AG, Bergstrand M, Karlsson MO.
 
Each iteration consistes of the following three phases: First, parameter vectors will be simulated from the 
proposal density. Iteration 1 uses the
truncated multivariate normal distribution 
given by the covariance matrix output from NONMEM's covariance step.
Note that the precond script, see precond\_userguide.pdf, can often recover the covariance step
even if it failed when running the original model.
Alternatively, a file with simulated parameter vectors can be given directly as input and this simulation is skipped. The last approach is useful when it is
difficult to obtain a (faked) covariance matrix. Iteration 2 uses the density obtained from the resampling performed in phase 3 of the first iteration.

Second, each of the simulated parameter vectors will be evaluated on the original data (MAXEVAL=0).
Third, based on these evaluations, weights will be calculated for each of the parameter vectors and the vectors 
will be resampled according to these weights. 

The uncertainty covariance matrix of the parameters 
will be computed from the resampled parameter vectors of the last iteration.

Example
\begin{verbatim}
sir -samples=1000,2000 -resamples=500,1000 run10.mod
\end{verbatim}

\section{Input and options}
A model file is required on the command-line. 
If output file (lst) exists, then it is important that the control stream copy at the top of the lst-file matches the actual input model file
in terms of which parameters are present and which parameters are FIXED or SAME.
\begin{optionlist}
\optdefault{samples}{M1,M2}
Required. A comma-separated list of (usually two) integers, the number of parameter vectors to 
generate in each iteration. In each iteration the number needs to be greater than the number 
of resamples. A good starting point may be 5 times the number of resamples.
If option -rawres\_input is used, the first integer in the list will
not be used, but it must still be set so that the list length is equal to
list 'resamples'.
\nextopt
\optdefault{resamples}{m1,m2}
Required. A comma-separated list of (usually two) integers, the number of parameter vectors to resample 
in each iteration based on the weights
computed from delta ofv and the pdf. 
Only the resampled vectors will be used to compute the uncertainty (confidence intervals) around the model parameters. A good starting point may be 1000 resamples.
The list length must be equal to list 'samples'.
\nextopt
\optdefault{rawres\_input}{filename}
If rawres\_input is given, in the first iteration sir will read all parameter
vectors from this file, starting on line offset\_rawres+1 and skipping any that does not fulfill the filter rules, instead of
running a full first iteration with sampling and resampling.
This option is not allowed together with covmat\_input. 

The raw results file must contain at least as many 
samples as the input '-resamples item 1' to sir, and this number must at the very least
be as large as the number of estimated parameters (also counting off-diagonals)
for it to be possible to obtain an empirical covariance matrix with full rank.
The labels for  THETA/OMEGA/SIGMA 
in the file must match the labels in the model given as input 
to sir, the theta columns must be directly followed by the omega columns 
which must be directly followed by the sigma columns, and the first or
second column must have header model. Note that is is 
possible to generate a file with initial parameter estimates outside 
of PsN, as long as the file follows the format rules.
\nextopt
\optdefault{offset\_rawres}{N}
Default 1. The number of parameter sets to skip in rawres file. Only allowed in combination with rawres\_input.
\nextopt
\optdefault{in\_filter}{condition on numerical col}
Default not used. Only allowed in combination with rawres\_input.
\nextopt
\optname{with\_replacement}
Default not set. By default, resampling is performed without replacement, but setting this option gives resampling with replacement.
It is not possible to cap replacement at e.g. 5, replacement will be unlimited.
\nextopt
\optdefault{covmat\_input}{filename}
Not allowed together with rawres\_input. If given, this covariance matrix is
used in the first iteration
for sampling parameter vectors and for computing the PDF.
The matrix will not be used in any but the first iteration. 
The format of the file is similar to a NONMEM-generated .cov-file except 
that the \verb|TABLE NO.| line should be omitted.
Fixed parameters do not have to be omitted, sir will filter them out. 
The covmat\_input file must be formatted to contain a space- or tab-separated  $N\times N$ symmetric covariance matrix.
The first line in the file must be a header with labels for THETA/OMEGA/SIGMA written as in a regular NONMEM .cov-file 
and a leading column called NAME: 
\begin{verbatim}
NAME THETA1 THETA2 ... SIGMA(1,1) ... OMEGA(1,1) ... 
\end{verbatim}
The NAME column contains the same parameter labels (to identify the rows).
The rows and columns must be sorted with THETAs first.

Please note that there is a PsN script called covmat that can be used to generate a covariance matrix from a raw\_results file.
\nextopt
\optdefault{inflation}{X}
Default is 1, which is the same as no inflation. If given, the covariance
matrix will in the first iteration be multiplied with a scalar $X$ multiple of the identity matrix
before the parameter vectors
are sampled from the truncated multivariate normal distribution.
The weights will also be computed based the inflated covariance matrix. 
Inflation is not used in any but the first iteration.
\nextopt
\optdefault{problems\_per\_file}{N}
Optional, default 100. The number of \$PROBLEM per model file when evaluating the parameter vectors
on the original data (running
MAXEVAL=0 or similar to get ofv:s for parameter vectors). Setting a higher value
decreases the overhead involved in running each control stream, but increases the 
risk of losing many samples in case a model file crashes. Setting -problems\_per\_file=1
gives maximum robustness to individual crashes, but also maximum overhead cost.
\nextopt
\optdefault{mceta}{N}
Optional. Sets option MCETA=N in \$ESTIMATION. Only allowed with NM7.3 and classical estimation methods.
\nextopt
\optname{copy\_data}
Default set. If option is set, the original data file
will be copied to the run directory.
If option is unset using -no-copy\_data, the absolute path to the original data file will be used in
\$DATA, and the data file will not be copied. This saves disk space.
\nextopt
\end{optionlist}

\subsection{Auto-generated R-plots from PsN}
\newcommand{\rplotsconditions}{The default sir template 
requires 
that R libraries
ggplot2, plyr, dplyr, caTools, reshape and tidyr are installed.
If the conditions are not fulfilled then no pdf will be generated,
see the .Rout file in the main run directory for error messages.}
\input{inputs/rplots_section_body.tex}

\subsubsection*{Diagnostic sir plots}
Diagnostic rplots for the last iteration of sir will be generated if option -rplots is set >0.

The first plot shows 3 comparative dOFV distributions: SIR, reference chi-square and original covariance matrix.
If on this plot the SIR curve is close to the reference chi-square curve it means that SIR results are good.

The second plot shows the number of resampled values in each bin of the parameter space. 
Each bin contains the same number of parameter values, which is set to 1/10 of the number of initial samples.
That is, Bin 1 corresponds to the lowest 10\% of simulated parameter values and Bin 10 to the highest 10\%.
If on this plot the number of resamples is around the dashed line, it means that the original covariance-matrix 
is a good approximation of the uncertainty and that SIR results are good.
If some bins have much more resamples than others, it means that the covariance matrix is different from the true uncertainty. 
SIR results remain an improvement over the original covariance-matrix but they could potentially be improved by modifying the 
original covariance matrix.
For example, one could inflate the variances of parameters that have more resamples than expected in the "outside" bins 
(diagonal or u-shaped lines).

The third plot shows the 95\% confidence interval for each parameter as determined by SIR and the original covariance matrix.
If on this plot the 95\% confidence intervals for one parameter are identical, it means that the covariance matrix 
is a good approximation of the uncertainty for this parameter.
If the 95\% confidence intervals differ between SIR and the covariance matrix, it means that the covariance matrix is 
different from the true uncertainty for this parameter.

\section{sir program workflow}
\subsubsection*{Setup} 
The sir program will run the input model unless the lst-file with results is already present. If the lst-file is present, it
is important that the control stream copy at the top of the lst-file matches the
actual input model file in terms of which parameters are estimated, 
FIXED or SAME, otherwise there will be a mis-match between which parameter estimates are read from the
lst-file and which estimates are needed for the sir procedure.

\subsubsection*{For each iteration $i$ (each item in list 'samples'):}
\begin{itemize}
\item[\underline{Step 1}] (Skipped in first iteration if rawres\_input is used.)
Simulate 'samples item $i$' parameter vectors from the 
covariance matrix.
In iteration 1 the covariance matrix is either from
the .cov-file given by NONMEM or given via option -covmat\_input,
and the matrix is inflated if option -inflation is set. 
In iteration 2 and higher 
the covariance matrix is the 
un-inflated
empirical covariance matrix of Box-Cox transformed resampled parameter vectors from
Step 6.

The Perl function Math::Random::random\_multivariate\_normal
is used for sampling. 
In iteration 1 the sampling is done on the original scale. 
In iteration 2 and higher
sampling is done on Box-Cox scale, and 
then the samples are back-transformed for boundary checks and evaluation.

If a vector (on the original scale) does not fulfill the constraints from \$THETA boundaries
and positive definiteness of \$OMEGA and
\$SIGMA blocks (as judged by a PsN-implemented Cholesky decomposition) 
then that vector is 
discarded and a new one is drawn.
\item[\underline{Step 2}] (Skipped in first iteration if rawres\_input is used.)
Calculate each vector $x$’s probability 
given the covariance matrix based on the formula for the probability 
density function (PDF) of a multivariate normal distribution:\\
\begin{math}
\frac{1}{\left(2\pi\right)^{k/2}\left(det\left(A\right)\right)^{1/2}} exp\left(-\frac{1}{2}(\left(x-\mu\right)A^{-1} \left(x-\mu\right)^T\right)
\end{math}
\\
where $k$ is the number of dimensions, 
$\mu$ is the vector of expectations and $A$ is the (possibly inflated) covariance matrix.
The values are normalized with the PDF for the vector of expectations $\mu$, giving\\
\begin{math}
relPDF=exp\left(-\frac{1}{2}(\left(x-\mu\right)A^{-1} \left(x-\mu\right)^T\right)
\end{math}
\\
NB 1: In iteration 1 the NONMEM covariance matrix is used as input (unless option -covmat\_input used), the inverse covariance matrix
output by NONMEM is not read.
NB 2: In iteration 2 and higher the vectors, including $\mu$, and covariance matrix are on Box-Cox scale.
\item[\underline{Step 3}] (Skipped in first iteration if rawres\_input is used.)
Evaluate the (original scale) parameter vectors on the original data.
Create model files with up to 100 \$PROBLEM based on the original model file but setting MAXEVAL=0
and replacing inits of nth \$PROBLEM with nth parameter vector on original scale, and also set MCETA if option -mceta was used. Compute dOFV 
(delta-OFV, reference is input model ofv) and store in raw results file for this iteration.
\item[\underline{Step 4}] (Skipped in first iteration if rawres\_input is used.)
Calculate the weights as the ratio $\frac{e^{-0.5\cdot dOFV}}{relPDF}$ and store in raw results file for this iteration. 
Resample 'resamples item $i$' parameter vectors based on these weights, with or without replacement depending on option -with\_replacement. 
Store the number of times each vector was resampled in raw results file for this iteration.
\item[\underline{Step 5}]
If iteration 1 \emph{and} rawres\_input is used: Read the first 'resamples item 1' parameter vectors
from file rawres\_input, using offset\_rawres and in\_filter (if set).
Otherwise read the resampled vectors from Step 4, using multiple copies for vectors that were resampled more than once (only possible if -with\_replacement was set).
\item[\underline{Step 6}]
If \emph{not} last iteration: 
For each parameter, use the 'resamples item $i$' individual values to find the Box-Cox transformation that maximizes the correlation with the normal density.
Do not allow $\lambda$ less than -3 or larger than +3. The  $\lambda$ used is allowed to differ from the true optimal  $\lambda$
by at most $0.2$.
Compute the covariance matrix for the Box-Cox transformed resampled parameter vectors.

\noindent If last iteration: 
Compute the covariance matrix for the resampled parameters on original scale, 
store in sir\_results.csv. 
Compute univariate confidence intervals and store in sir\_results.csv.
\end{itemize}

\section{Output}
\begin{itemize}
\item raw\_results for each iteration with added columns for\\
\begin{tabular}{ll}
\bf{sample.id} & A unique number\\
\bf{deltaofv} & $\mathrm{ofv} - \mathrm{original}\mbox{\tt\string_}\mathrm{model}\mbox{\tt\string_}\mathrm{ofv}$\\
\bf{likelihood\_ratio} & $e^{-0.5\cdot \mathrm{deltaofv}}$ \\
\bf{relPDF} & relative PDF \\
\bf{importance\_ratio} & $\mathrm{likelihood}\mbox{\tt\string_}\mathrm{ratio}/\mathrm{relPDF}$\\
\bf{probability\_resample} & $\mathrm{importance}\mbox{\tt\string_}\mathrm{ratio}/\sum{\mathrm{importance}\mbox{\tt\string_}\mathrm{ratio}}$ \\
\bf{resamples} & number of actual resamples with random seed used\\
\end{tabular}
NB: If -rawres\_input is used there is no raw\_results file for the first iteration.
\item sir\_results.csv with percentiles and empirical covariance matrix
\item <modelname>\_sir.cov with the empirical covariance matrix in NONMEM-like format, i.e. 
      fixed width space separated with generic headers in order THETA, SIGMA, OMEGA.
\item if option -rplots>0: A file PsN\_sir\_plots.pdf with diagnostic sir plots.
\item For all but the last iteration: A file with the Box-Cox $\lambda$ for each parameter, plus the $\delta$ used to shift
the values to positive before Box-Cox transformation. If the $\lambda$ column is empty it means that no transformation was
needed because the parameter was already close to normally distributed.
\end{itemize}


\section{Troubleshooting}
\subsection*{Mismatch between input files}
If you use the covmat\_input option and get an error message similar to
\begin{verbatim}
Number of parameters 122 in covmat_input does not match 
number 123 of estimated parameters in input model
\end{verbatim}
then the most likely cause is that there is a mismatch between the input files. Make sure that the number of
estimated parameters (the number of parameters, the FIXED and SAME settings, the DIAGONAL or BLOCK omega/sigma)
match between the control stream copy at the beginning of the pre-existing lst-file and the input model file.
\subsection*{raw\_results file with \$PRIOR}
If the input model has \$PRIOR NWPRI, and the priors are encoded with \$THETA, \$OMEGA and \$SIGMA instead of the
prior-specific records \$THETAP, \$THETAPV, \$OMEGAP etc, then PsN will not be able to handle the parameter column
headers correctly in the raw\_results file. The solution is to always use the prior-specific records for
encoding the prior information.
\subsection*{Error message that covariance matrix not positive definite}
The sir program will use a Cholesky decomposition without pivoting for processing of the covariance matrix. 
This works in most cases, but in some rare case this algorithm can fail for a matrix that is mathematically positive definite
but requires pivoting for Cholesky decomposition to work.
When this happens, sir will stop with an error message saying that the covariance matrix is numerically not positive definite.
Then the user must manually modify the covariance matrix to improve its numerical properties (for example increase the diagonal elements
and/or change the order of the parameters so that pivoting is not necessary),
and then use option -covmat\_input to give the modified matrix as input to sir. 

\end{document}

\section{Suggested new workflow}
NB: if -rawres\_input is specified, then the process starts
at step 6 using those vectors as the 'resamples\_1' parameter vectors. 
\begin{itemize}
\item[\underline{Setup}] The sir program will run the input model unless the lst-file with results is already present. 
If the lst-file is present, it
is important that the control stream copy at the top of the lst-file matches the
actual input model file in terms of which parameters are estimated, 
FIXED or SAME, otherwise there will be a mis-match between which parameter estimates are read from the
lst-file and which estimates are needed for the sir procedure.
\item[\underline{Step 1}] Simulate 'samples\_1' parameter vectors from the 
(possibly inflated)
covariance matrix, i.e. the .cov-file given by NONMEM 
or the matrix given via option -covmat\_input. PsN uses the Perl function\\ 
Math::Random::random\_multivariate\_normal
for sampling. If a vector does no fulfill the constraints from \$THETA boundaries
and positive definiteness of \$OMEGA and
\$SIGMA blocks (as judged by a PsN-implemented Cholesky decomposition) 
then that vector is 
discarded and a new one is drawn.
\item[\underline{Step 2}] Calculate each vector $x$’s probability 
given the covariance matrix based on the formula for the probability 
density function (PDF) of a multivariate normal distribution:\\
\begin{math}
\frac{1}{\left(2\pi\right)^{k/2}\left(det\left(A\right)\right)^{1/2}} exp\left(-\frac{1}{2}(\left(x-\mu\right)A^{-1} \left(x-\mu\right)^T\right)
\end{math}
\\
where $k$ is the number of dimensions, 
$\mu$ is the vector of expectations and $A$ is the (possibly inflated) covariance matrix.
The values are normalized with the PDF for the vector of expectations $\mu$, giving\\
\begin{math}
relPDF=exp\left(-\frac{1}{2}(\left(x-\mu\right)A^{-1} \left(x-\mu\right)^T\right)
\end{math}
\\
NB: NONMEM covariance matrix is used as input, the inverse covariance matrix
output by NONMEM is not used.
\item[\underline{Step 3}] evaluate the parameter vectors on the original data.
Create model files with up to 100 \$PROBLEM based on the original model file but setting MAXEVAL=0
and replacing inits of nth \$PROBLEM with nth parameter vector, and also set MCETA if option -mceta was used. Compute dOFV 
(delta-OFV, reference is input model ofv) and store in raw\_results\_1.csv.

\item[\underline{Step 4}] calculate the weights as the ratio $\frac{e^{-0.5\cdot dOFV}}{relPDF}$ and store in 
raw\_results\_1.csv. 
\item[\underline{Step 5}] Resample 'resamples\_1' parameter vectors based on weights from above step, 
with or without replacement depending on option -with\_replacement. 
Store the number of times each vector was resampled in raw\_results\_1.csv.
\item[\underline{Step 6}] Box-Cox transform each parameter separately based on the samples from Step 5. Do not allow
$\lambda$ less than -3 or larger than +3. Use the $\lambda$ that maximizes the correlation between the normal distribution and
the distribution of the transformed parameter. The  $\lambda$ used is allowed to differ from the true optimal  $\lambda$
by at most $0.2$.
\item[\underline{Step 7}] Determine the means and empirical variance-covariance matrix of 
transformed parameter vectors.
\item[\underline{Step 8}] (Repeat Step 1) Sample 'samples\_2' parameter vectors 
with the new covariance matrix and transformed parameters.
Discard samples that, after back-transformation to original scale, do not
fulfill \$THETA boundary conditions and \$OMEGA/\$SIGMA positive definiteness, and instead draw new sample.
\item[\underline{Step 9}] (Repeat Step 2) Calculate each vector's probability, 
use new covariance matrix and Box-Cox transformed parameter vectors for computing each vector's relPDF.
\item[\underline{Step 10}] (Repeat Step 3) Evaluate the sampled parameter vectors, in original scale (back-transformed from Box-Cox), on the original data.
\item[\underline{Step 11}] (Repeat Step 4) Calculate the weights, 
where weights calculation uses relPDF from step 9 and dOFV from Step 10. 
Store in raw\_results\_2.csv. 
\item[\underline{Step 12}] (Repeat Step 5) Resample 'resamples\_2' original scale parameter vectors based on weights from above step, 
with or without replacement depending on option -with\_replacement. 
Store the number of times each vector was resampled in raw\_results\_2.csv.
\item[\underline{Step 13}] Compute final results from Step 12 (parameter vectors on original scale).
\end{itemize}

\end{document}

\subsubsection*{setup}
\begin{enumerate}
\item Count items in parameter vector to get $N$.
\item Unless have quantile vector for $N$ stored from before:\\ Compute vector $Q$ for $i=1\ldots N$,
\begin{math}
\left(
Q_i=\Phi^{-1}\left(\frac{i-0.5}{N}\right)
\right)
\end{math}
using built-in Perl functions. Also compute $\frac{\sum_i{Q}}{N}$ and 
$\sqrt{\sum_i{Q^2}-\frac{\left(\sum_i{Q}\right)^2}{N}}$\\ Store results.
\item Sort parameter vector from smallest to largest to get vector $sorted$.
\item If $sorted[0]\leq 0$ then compute $\Delta=abs\left(sorted[0]+\delta\right)$ and add scalar $\Delta$ to $sorted$.
Store $\Delta$.
\item Evaluate $r(\lambda)$ for starting values for secant algorithm
\item Run secant algorithm until stops, find optimal value of $\lambda$ and corresponding transformed sorted positive
vector. Store $\lambda$
\end{enumerate}

\subsubsection*{Box-Cox}
Must have $x>0$, so if any $p$ leq 0 then add $abs(p_{min})+\delta$ to all $p$ before Box-Cox.
\noindent
\begin{math}
\lambda = 0: x_{\lambda}=log(p)\\
\lambda\neq 0: x_{\lambda}=\frac{p^{\lambda}-1}{\lambda}
\end{math}

\begin{math}
\frac{dx}{d\lambda}, \lambda=0: undef\\
\frac{dx}{d\lambda}, \lambda\neq 0: \frac{d}{d\lambda}\frac{p^{\lambda}-1}{\lambda}=\frac{d}{d\lambda}\frac{e^{\lambda log{p}}-1}{\lambda}=
\frac{\lambda e^{\lambda log{p}}log{p} -(e^{\lambda log{p}}-1) }{\lambda^2}=\frac{1}{\lambda}\left(p^{\lambda}log{p} - \frac{p^{\lambda}-1}{\lambda}\right)
\end{math}

\subsubsection*{q-q-plot}
Form N pairs
\begin{math}
\left(
\Phi^{-1}\left(\frac{i-0.5}{N}\right), x_i
\right)
\end{math}
where $\Phi^{-1}$ is the inverse CDF of the normal density and $x_i$ denotes the $i$th sorted value
of the Box-Cox transformed data.
For inverse CDF use Perl Math::CDF::qnorm function.
Compare with Statistics::Distributions::udistr(1-z) where $z=\frac{i-0.5}{N}$

\subsubsection*{Pearson's r}
x and y do not need to have mean 0. x could Box-Cox transformed (g), y could be inverse CDF.
\begin{math}
r=\frac{\sum{xy}-\frac{\sum{x}\sum{y}}{N}}
{\sqrt{\sum{x^2}-\frac{\left(\sum{x}\right)^2}{N}}\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}}
\end{math}
When y is inverse CDF then $\sum_iy_i$ is 0, giving 
\begin{math}
r=\frac{\sum{xy}}
{\sqrt{\sum{x^2}-\frac{\left(\sum{x}\right)^2}{N}}\sqrt{\sum{y^2}}}\\
=\frac{f(\lambda)}{g(\lambda)}
\end{math}

\begin{math}
f(\lambda)=\sum{xy}=\sum_i \left(y_i\frac{p_i^{\lambda}-1}{\lambda}\right)
\end{math}

\begin{math}
\frac{df(\lambda)}{d\lambda}
=\sum_i\left(y_i\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)\right)
\end{math}


\begin{math}
g(\lambda)=
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{0.5} 
\sqrt{\sum{y^2}}
\end{math}

\begin{math}
\frac{dg(\lambda)}{d\lambda}=
\sqrt{\sum{y^2}}\cdot
0.5\cdot\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\cdot\\
\left(
\sum_i2\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{2}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right)
\end{math}

\begin{math}
=
\sqrt{\sum{y^2}}\cdot
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\cdot\\
\left(
\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right)
\end{math}

\begin{math}
\frac{dr}{d\lambda}=\frac{f'g-fg'}{g^2}=g^{-2}\cdot\left(f'g-fg'\right)
\end{math}

\begin{multline}
\frac{dr}{d\lambda}=
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-1} 
\left(\sum{y^2}\right)^{-1}\cdot  \\
[
\left[
\sum_i\left(\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)y_i\right)
\right]  \\
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{0.5} 
\sqrt{\sum{y^2}}  \\
-
\left[\sum_i \left(y_i\frac{p_i^{\lambda}-1}{\lambda}\right)\right]\cdot\\
\sqrt{\sum{y^2}}\cdot
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\cdot\\
\left[
\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right]
]
\end{multline}


\begin{multline}
\frac{dr}{d\lambda}=
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\left(\sum_i{y_i^2}\right)^{-0.5}\cdot  \\
[
\left[
\sum_i\left(\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)y_i\right)
\right]  \\
-
\left[\sum_i \left(y_i\frac{p_i^{\lambda}-1}{\lambda}\right)\right]\cdot\\
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-1} 
\cdot\\
\left[
\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right]
]
\end{multline}

\begin{math}
r=\left(\sum_i{x_i^2}-\frac{\left(\sum_i{x_i}\right)^2}{N}\right)^{-0.5} 
\left(\sum_i{y_i^2}\right)^{-0.5}\cdot
\left(\sum_i{y_ix_i}\right)
\end{math}

\begin{multline}
\frac{dr}{d\lambda}=
\left(\sum_i{x_i^2}-\frac{\left(\sum_i{x_i}\right)^2}{N}\right)^{-0.5} 
\left(\sum_i{y_i^2}\right)^{-0.5}\cdot\frac{1}{\lambda}\cdot  \\
[
\sum_i\left(y_ip_i^{\lambda}log{p_i}\right) -  
\sum_i\left(x_iy_i\right)
-\\
\frac{\left(\sum_i{y_ix_i}\right) \cdot
\left[
\sum_i \left(x_ip_i^{\lambda}log{p_i}\right) - \sum_i \left(x_i^2\right)
-\left( \sum_i \left(p_i^{\lambda}log{p_i}\right) -\sum_i \left(x_i\right) \right)\frac{\left(\sum_i{x_i}\right)}{N} 
\right]}
{\left(\sum_i{x_i^2}-\frac{\left(\sum_i{x_i}\right)^2}{N}\right)}
]
\end{multline}

\subsubsection*{Intermediate sums needed}
\begin{enumerate}
\item sum\_x: $\sum_i{x_i}$
\item sum\_xsquare: $\sum_i{x_i^2}$
%\item sum\_y: $\sum_i{y_i}$
\item sum\_ysquare: $\sum_i{y_i^2}$
\item sum\_xy: $\sum_i{y_ix_i}$
\item sum\_logterm: $\sum_i{p_i^{\lambda}log{p_i}}$
\item sum\_xlogterm: $\sum_i{x_ip_i^{\lambda}log{p_i}}$
\item sum\_ylogterm: $\sum_i{y_ip_i^{\lambda}log{p_i}}$

\end{enumerate}

\subsubsection*{secant method}
Algorithm secant method (p 366 mathematics handbook):\\
\begin{math}
\lambda_{n+1}=\lambda_n-
r^{'}\left(\lambda_{n}\right)\cdot\frac{\lambda_n-\lambda_{n-1}}{r^{'}\left(\lambda_n\right)-r^{'}\left(\lambda_{n-1}\right)}
\end{math}\\
Stop when either
\begin{enumerate}
\item $\lambda_{n+1}\geq\lambda_{max}$
\item $\lambda_{n+1}\leq-\lambda_{max}$
\item \begin{math}abs\left(r\left(\lambda_n\right)-r\left(\lambda_{n-1}\right)\right)\leq \delta_{r}
\end{math}
\item
\begin{math}
abs\left(r\left(\lambda_{n}\right)\cdot\frac{\lambda_n-\lambda_{n-1}}{r\left(\lambda_n\right)-r\left(\lambda_{n-1}\right)}\right)\leq\delta_{\lambda}
\end{math}
\end{enumerate}
After stopping criteria met, choose $\lambda$ that gave largest $r$.

\end{document}

\subsubsection*{General y}
\begin{math}
r=\frac{\sum{xy}-\frac{\sum{x}\sum{y}}{N}}
{\sqrt{\sum{x^2}-\frac{\left(\sum{x}\right)^2}{N}}\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}}=\frac{f}{g}
\end{math}


\begin{math}
f(\lambda)=\sum{xy}-\frac{\sum{x}\sum{y}}{N}
=
\sum_i \left(y_i\frac{p_i^{\lambda}-1}{\lambda}\right) - \left(\sum_i\frac{p_i^{\lambda}-1}{\lambda}\right)\frac{\sum_iy_i}{N}
\end{math}

\begin{math}
\frac{df(\lambda)}{d\lambda}
=\sum_i\left(y_i\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)\right)
-\left( \sum_i\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)\right)
\frac{\sum_iy_i}{N} \\
\end{math}


\begin{math}
g(\lambda)=
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{0.5} 
\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}
\end{math}

\begin{math}
\frac{dg(\lambda)}{d\lambda}=
\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}\cdot
0.5\cdot\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\cdot\\
\left(
\sum_i2\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{2}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right)
\end{math}

\begin{math}
=
\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}\cdot
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\cdot\\
\left(
\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right)
\end{math}

\begin{math}
\frac{dr}{d\lambda}=\frac{f'g-fg'}{g^2}=g^{-2}\cdot\left(f'g-fg'\right)
\end{math}

\begin{multline}
\frac{dr}{d\lambda}=
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-1} 
\left(\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}\right)^{-1}\cdot  \\
[
\left[
\sum_i\left(\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)y_i\right) -  
\left(\sum_i\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)\right)\left(\sum_iy_i\right)\frac{1}{N}
\right]  \\
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{0.5} 
\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}  \\
-
\left[\sum_i \left(y_i\frac{p_i^{\lambda}-1}{\lambda}\right) - \left(\sum_i\frac{p_i^{\lambda}-1}{\lambda}\right)\frac{\sum_iy_i}{N}\right]\cdot\\
\sqrt{\sum{y^2}-\frac{\left(\sum{y}\right)^2}{N}}\cdot
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\cdot\\
\left[
\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right]
]
\end{multline}

\begin{multline}
\frac{dr}{d\lambda}=
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-0.5} 
\left(\sum_i{y_i^2}-\frac{\left(\sum_i{y_i}\right)^2}{N}\right)^{-0.5}\cdot  \\
[
\left[
\sum_i\left(\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)y_i\right) -  
\left(\sum_i\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)\right)\frac{\left(\sum_iy_i\right)}{N}
\right]  \\
-
\left[\sum_i \left(y_i\frac{p_i^{\lambda}-1}{\lambda}\right) - \left(\sum_i\frac{p_i^{\lambda}-1}{\lambda}\right)\frac{\left(\sum_iy_i\right)}{N}\right]\cdot\\
\left(\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda}\right)^2-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right)^2  \right)^{-1} 
\cdot\\
\left[
\sum_i\left(\frac{p_i^{\lambda}-1}{\lambda} \right)\frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right)
-\frac{1}{N}\left(\sum_i \frac{p_i^{\lambda}-1}{\lambda}\right) \left(\sum_i \frac{1}{\lambda}\left(p_i^{\lambda}log{p_i}-\frac{p_i^{\lambda}-1}{\lambda}\right) \right)
\right]
]
\end{multline}

\newpage

\begin{math}
r=\left(\sum_i{x_i^2}-\frac{\left(\sum_i{x_i}\right)^2}{N}\right)^{-0.5} 
\left(\sum_i{y_i^2}-\frac{\left(\sum_i{y_i}\right)^2}{N}\right)^{-0.5}\cdot
\left(\sum_i{y_ix_i} - \frac{\left(\sum_ix_i\right)\left(\sum_iy_i\right)}{N}\right)
\end{math}

\begin{multline}
\frac{dr}{d\lambda}=
\left(\sum_i{x_i^2}-\frac{\left(\sum_i{x_i}\right)^2}{N}\right)^{-0.5} 
\left(\sum_i{y_i^2}-\frac{\left(\sum_i{y_i}\right)^2}{N}\right)^{-0.5}\cdot\frac{1}{\lambda}\cdot  \\
[
\left[
\sum_i\left(y_ip_i^{\lambda}log{p_i}\right) -  
\sum_i\left(x_iy_i\right) -  
\left( \sum_i\left(p_i^{\lambda}log{p_i}\right) - \sum_i\left(x_i\right)  \right)\frac{\left(\sum_iy_i\right)}{N}
\right]  \\
-
\left(\sum_i{y_ix_i} - \frac{\left(\sum_ix_i\right)\left(\sum_iy_i\right)}{N}\right)\cdot
\left(\sum_i{x_i^2}-\frac{\left(\sum_i{x_i}\right)^2}{N}\right)^{-1} 
\cdot\\
\left[
\sum_i \left(x_ip_i^{\lambda}log{p_i}\right) - \sum_i \left(x_i^2\right)
-\left( \sum_i \left(p_i^{\lambda}log{p_i}\right) -\sum_i \left(x_i\right) \right)\frac{\left(\sum_i{x_i}\right)}{N} 
\right]
]
\end{multline}

\end{document}
