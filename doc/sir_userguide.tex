\input{inputs/format_header.tex}
\guidetitle{SIR user guide}{2015-04-15}

\begin{document}

\maketitle

\newcommand{\guidetoolname}{sir}

\section{Introduction}
The sir program calculates uncertainty
on model parameters for the input model using the Sampling Importance Resampling (SIR) procedure.
The SIR procedure is described in\\
\emph{Application of Sampling Importance Resampling to estimate parameter uncertainty distributions}, 
PAGE 22 (2013) Abstr 2907, Dosne AG, Bergstrand M, Karlsson MO.\\
and in\\
\emph{Determination of Appropriate Settings in the Assessment of Parameter Uncertainty Distributions 
using Sampling Importance Resampling (SIR)}, 
PAGE 24 (2015) Abstr 3546, Dosne AG, Bergstrand M, Karlsson MO.
 
First, parameter vectors will be simulated from the truncated multivariate normal distribution 
given by the covariance matrix output from NONMEM's covariance step.
Note that the precond script, see precond\_userguide.pdf, can often recover the covariance step
even if it failed when running the original model.
Alternatively, a file with simulated parameter vectors can be given directly as input and this simulation is skipped. The last approach is useful when it is
difficult to obtain a (faked) covariance matrix.

Second, each of the simulated parameter vectors will be evaluated on the original data (MAXEVAL=0).
Third, based on these evaluations, weights will be calculated for each of the parameter vectors and the vectors 
will be resampled according to these weights. Finally, the uncertainty covariance matrix of the parameters 
will be computed from the resampled parameter vectors.

Example
\begin{verbatim}
sir -samples=5000 -resamples=1000 run0.mod
\end{verbatim}

\section{Input and options}
A model file is required on the command-line. 
If output file (lst) exists, then it is important that the control stream copy at the top of the lst-file matches the actual input model file
in terms of which parameters are present and which parameters are FIXED or SAME.
\begin{optionlist}
\optdefault{samples}{N}
Required. The number of parameter vectors to generate. Needs to be greater than the number of resamples. A good starting point may be 5 times the number of resamples.
\nextopt
\optdefault{resamples}{N}
Required. The number of parameter vectors to resample based on the weights
computed from delta ofv and the pdf. Only these will be used to compute the uncertainty (confidence intervals) around the model parameters. A good starting point may be 1000 resamples.
\nextopt
\optdefault{rawres\_input}{filename}
If rawres\_input is given, sir will take samples sets of parameter
vectors from this file, starting on line offset\_rawres+1, instead of
drawing samples from a truncated multivariate normal distribution 
based on the input model parameter estimates and 
covariance matrix.
This option is not allowed together with covmat\_input. 
When rawres\_input is given, all vectors will be assigned the same PDF, meaning that only delta-ofv will influence the resampling.

The raw results file must contain at least as many 
samples as the input -samples to sir, the labels for  THETA/OMEGA/SIGMA 
in the file must match the labels in the model given as input 
to sir, the theta columns must be directly followed by the omega columns 
which must be directly followed by the sigma columns, and the first or
second column must have header model. Note that is is 
possible to generate a file with initial parameter estimates outside 
of PsN, as long as the file follows the format rules.
\nextopt
\optdefault{offset\_rawres}{N}
Default 1. The number of parameter sets to skip in rawres file. Only allowed in combination with rawres\_input.
\nextopt
\optdefault{in\_filter}{condition on numerical col}
Default not used. Only allowed in combination with rawres\_input.
\nextopt
\optname{with\_replacement}
Default not set. By default, resampling is performed without replacement, but setting this option gives resampling with replacement.
It is not possible to cap replacement at e.g. 5, replacement will be unlimited.
\nextopt
\optdefault{covmat\_input}{filename}
Not allowed together with rawres\_input. If given, this covariance matrix is
used for sampling parameter vectors and for computing the PDF. 
The format of the file is similar to a NONMEM-generated .cov-file except 
that the \verb|TABLE NO.| line should be omitted.
Fixed parameters do not have to be omitted, sir will filter them out. 
The covmat\_input file must be formatted to contain a space- or tab-separated  $N\times N$ symmetric covariance matrix.
The first line in the file must be a header with labels for THETA/OMEGA/SIGMA written as in a regular NONMEM .cov-file 
and a leading column called NAME: 
\begin{verbatim}
NAME THETA1 THETA2 ... SIGMA(1,1) ... OMEGA(1,1) ... 
\end{verbatim}
The NAME column contains the same parameter labels (to identify the rows).
The rows and columns must be sorted with THETAs first.

Please note that there is a PsN script called covmat that can be used to generate a covariance matrix from a raw\_results file.
\nextopt
\optdefault{inflation}{X}
Default is 1, which is the same as no inflation. If given, the covariance
matrix will be multiplied with a scalar $X$ multiple of the identity matrix
before the parameter vectors
are sampled from the truncated multivariate normal distribution.
The weights will also be computed based the inflated covariance matrix. 
\nextopt
\optdefault{problems\_per\_file}{N}
Optional, default 100. The number of \$PROBLEM per model file when running
MAXEVAL=0 or similar to get ofv:s for parameter vectors. Setting a higher value
decreases the overhead involved in running each control stream, but increases the 
risk of losing many samples in case a model file crashes. Setting -problems\_per\_file=1
gives maximum robustness to individual crashes, but also maximum overhead cost.
\nextopt
\optdefault{mceta}{N}
Optional. Sets option MCETA=N in \$ESTIMATION. Only allowed with NM7.3 and classical estimation methods.
\nextopt
\optname{copy\_data}
Default set. If option is set, the original data file
will be copied to the run directory.
If option is unset using -no-copy\_data, the absolute path to the original data file will be used in
\$DATA, and the data file will not be copied. This saves disk space.
\nextopt
\end{optionlist}

\subsection{Auto-generated R-plots from PsN}
\newcommand{\rplotsconditions}{The default sir template 
requires 
that R libraries
ggplot2, plyr, dplyr, caTools, reshape and tidyr are installed.
If the conditions are not fulfilled then no pdf will be generated,
see the .Rout file in the main run directory for error messages.}
\input{inputs/rplots_section_body.tex}

\subsubsection*{Diagnostic sir plots}
Diagnostic rplots for sir will be generated if option -rplots is set >0.

The first plot shows 3 comparative dOFV distributions: SIR, reference chi-square and original covariance matrix.
If on this plot the SIR curve is close to the reference chi-square curve it means that SIR results are good.

The second plot shows the number of resampled values in each bin of the parameter space. 
Each bin contains the same number of parameter values, which is set to 1/10 of the number of initial samples.
That is, Bin 1 corresponds to the lowest 10\% of simulated parameter values and Bin 10 to the highest 10\%.
If on this plot the number of resamples is around the dashed line, it means that the original covariance-matrix 
is a good approximation of the uncertainty and that SIR results are good.
If some bins have much more resamples than others, it means that the covariance matrix is different from the true uncertainty. 
SIR results remain an improvement over the original covariance-matrix but they could potentially be improved by modifying the 
original covariance matrix.
For example, one could inflate the variances of parameters that have more resamples than expected in the "outside" bins 
(diagonal or u-shaped lines).

The third plot shows the 95\% confidence interval for each parameter as determined by SIR and the original covariance matrix.
If on this plot the 95\% confidence intervals for one parameter are identical, it means that the covariance matrix 
is a good approximation of the uncertainty for this parameter.
If the 95\% confidence intervals differ between SIR and the covariance matrix, it means that the covariance matrix is 
different from the true uncertainty for this parameter.

\section{sir program workflow}
\begin{itemize}
\item[\underline{Setup}] The sir program will run the input model unless the lst-file with results is already present. If the lst-file is present, it
is important that the control stream copy at the top of the lst-file matches the
actual input model file in terms of which parameters are estimated, 
FIXED or SAME, otherwise there will be a mis-match between which parameter estimates are read from the
lst-file and which estimates are needed for the sir procedure.
\item[\underline{Step 1}] Simulate 'samples' parameter vectors from the 
(possibly inflated)
covariance matrix, i.e. the .cov-file given by NONMEM 
or the matrix given via option -covmat\_input. PsN uses the Perl function\\ 
Math::Random::random\_multivariate\_normal
for sampling. If a vector does no fulfill the constraints from \$THETA boundaries
and positive definiteness of \$OMEGA and
\$SIGMA blocks (as judged by a PsN-implemented Cholesky decomposition) 
then that vector is 
discarded and a new one is drawn.
NB: Sampling is \emph{not} performed if -rawres\_input is specified.
\item[\underline{Step 2}] Calculate each vector $x$â€™s probability 
given the covariance matrix based on the formula for the probability 
density function (PDF) of a multivariate normal distribution:\\
\begin{math}
\frac{1}{\left(2\pi\right)^{k/2}\left(det\left(A\right)\right)^{1/2}} exp\left(-\frac{1}{2}(\left(x-\mu\right)A^{-1} \left(x-\mu\right)^T\right)
\end{math}
\\
where $k$ is the number of dimensions, 
$\mu$ is the vector of expectations and $A$ is the (possibly inflated) covariance matrix.
The values are normalized with the PDF for the vector of expectations $\mu$, giving\\
\begin{math}
relPDF=exp\left(-\frac{1}{2}(\left(x-\mu\right)A^{-1} \left(x-\mu\right)^T\right)
\end{math}
\\
NB 1: NONMEM covariance matrix is used as input, the inverse covariance matrix
output by NONMEM is not used.
NB 2: If -rawres\_input is specified the probability of each vector will be set equal to 1.
\item[\underline{Step 3}] evaluate the parameter vectors on the original data.
Create model files with up to 100 \$PROBLEM based on the original model file but setting MAXEVAL=0
and replacing inits of nth \$PROBLEM with nth parameter vector, and also set MCETA if option -mceta was used. Compute dOFV 
(delta-OFV, reference is input model ofv) and store in raw\_results.csv.
\item[\underline{Step 4}] calculate the weights as the ratio $\frac{e^{-0.5\cdot dOFV}}{relPDF}$ and store in raw\_results.csv. 
Resample 'resamples' parameter vectors based on these weights, with or without replacement depending on option -with\_replacement. 
Store the number of times each vector was resampled in raw\_results.csv.
Compute the covariance matrix for the resampled parameters (variances and covariances), 
store in sir\_results.csv. 
Compute univariate confidence intervals and store in sir\_results.csv.
\end{itemize}

\section{Output}
\begin{itemize}
\item raw\_results.csv with added columns for\\
\begin{tabular}{ll}
\bf{sample.id} & A unique number\\
\bf{deltaofv} & $\mathrm{ofv} - \mathrm{original}\mbox{\tt\string_}\mathrm{model}\mbox{\tt\string_}\mathrm{ofv}$\\
\bf{likelihood\_ratio} & $e^{-0.5\cdot \mathrm{deltaofv}}$ \\
\bf{relPDF} & relative PDF \\
\bf{importance\_ratio} & $\mathrm{likelihood}\mbox{\tt\string_}\mathrm{ratio}/\mathrm{relPDF}$\\
\bf{probability\_resample} & $\mathrm{importance}\mbox{\tt\string_}\mathrm{ratio}/\sum{\mathrm{importance}\mbox{\tt\string_}\mathrm{ratio}}$ \\
\bf{resamples} & number of actual resamples with random seed used\\
\end{tabular}
\item sir\_results.csv with percentiles and empirical covariance matrix
\item <modelname>\_sir.cov with the empirical covariance matrix in NONMEM-like format, i.e. 
      fixed width space separated with generic headers in order THETA, SIGMA, OMEGA.
\item if option -rplots>0: A file PsN\_sir\_plots.pdf with diagnostic sir plots.
\end{itemize}


\section{Troubleshooting}
\subsection*{Mismatch between input files}
If you use the covmat\_input option and get an error message similar to
\begin{verbatim}
Number of parameters 122 in covmat_input does not match 
number 123 of estimated parameters in input model
\end{verbatim}
then the most likely cause is that there is a mismatch between the input files. Make sure that the number of
estimated parameters (the number of parameters, the FIXED and SAME settings, the DIAGONAL or BLOCK omega/sigma)
match between the control stream copy at the beginning of the pre-existing lst-file and the input model file.
\subsection*{raw\_results file with \$PRIOR}
If the input model has \$PRIOR NWPRI, and the priors are encoded with \$THETA, \$OMEGA and \$SIGMA instead of the
prior-specific records \$THETAP, \$THETAPV, \$OMEGAP etc, then PsN will not be able to handle the parameter column
headers correctly in the raw\_results file. The solution is to always use the prior-specific records for
encoding the prior information.
\subsection*{Error message that covariance matrix not positive definite}
The sir program will use a Cholesky decomposition without pivoting for processing of the covariance matrix. 
This works in most cases, but in some rare case this algorithm can fail for a matrix that is mathematically positive definite
but requires pivoting for Cholesky decomposition to work.
When this happens, sir will stop with an error message saying that the covariance matrix is numerically not positive definite.
Then the user must manually modify the covariance matrix to improve its numerical properties (for example increase the diagonal elements
and/or change the order of the parameters so that pivoting is not necessary),
and then use option -covmat\_input to give the modified matrix as input to sir. 
\end{document}

