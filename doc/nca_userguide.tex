\input{inputs/format_header.tex}
\guidetitle{NCA user guide}

\begin{document}

\maketitle

\section{Introduction}
The PsN NCA can feed the nca R-script with simulated data. It is based on the simulation part of the vpc/npc.

\section{Running NCA}
Example:

\begin{verbatim}
nca run1.mod
\end{verbatim}

Input: a modelfile is required.

\begin{optionlist}
\optdefault{samples}{number}
The number of simulated datasets to generate. 1000 is the default. 
\nextopt
\optdefault{msfo}{file}
is optional, unless the model has \$NONP record then an msfo-file	is required. Use final parameter estimates from msfo-file instead of initial estimates from modelfile when simulating.
\nextopt
\optdefault{lst}{file}
is optional, but forbidden together with -msfo. Use final parameter estimates from this lst-file for the simulation. By default PsN will look for a file with the same name as the regular input model, or the simulation model if option -sim\_model is used, but with suffix .lst instead of .mod. If such a file is found then option -lst=$<$modelfile$>$.lst is set automatically. VPC does not perform estimation. 
\nextopt
\optdefault{columns}{var1,var2,...}
is optional. The columns option is a comma-separated list of variable names. All listed variables will be added to the nca table output.
\nextopt
\optdefault{sim\_model}{file}
is optional. Cannot be used together with -flip\_comments, -keep\_estimation or -noprediction. By default PsN will create a simulation model based on the  required input model, but by using option -sim\_model it is possible to use a separate input model for the simulations. PsN will remove \$COV and \$TABLE, change SEED and NSUBS in \$SIM, add a new \$TABLE and  update initial estimates if option -lst is set or add \$MSFI if option -msfo is used, but otherwise no changes will be made to the user defined simulation model. See section Modified models. Note that -lst will be set automatically if a file with the same name as the regular input model but with suffix lst intead of mod is found. 
\nextopt
\optname{flip\_comments}
is optional. Cannot be used together with -sim\_model, -keep\_estimation or -noprediction. By default PsN will create a simulation model based on the  required input model, but option -flip\_comments invokes a method for handling user-defined simulation code in the required input model. If option is set, PsN will create the simulation model by flipping comments (commented lines will be uncommented and vice versa) between the tags


\begin{verbatim}
;Sim_start
\end{verbatim}
and 
\begin{verbatim}
;Sim_end
\end{verbatim}
For example, if the required input model has lines
\begin{verbatim}
;Sim_start 
IGNORE(TYPE.EQ.1)
;ACCEPT(TYPE.EQ.1) 
;Sim_end
\end{verbatim}
then the MAXEVAL=0 model will be run as such and the simulation model will instead have lines
\begin{verbatim}
;IGNORE(TYPE.EQ.1)
ACCEPT(TYPE.EQ.1) 
\end{verbatim}
The tags may appear multiple times. Note that the tags must look exactly  as above or the editing will fail. When creating the simulation model PsN will remove \$COV and \$TABLE, change SEED and NSUBS in \$SIM, add a new \$TABLE and  update initial estimates if option -lst is set or add \$MSFI if option -msfo is used, but otherwise no changes will be made to the code. See section Modified models.\\
\nextopt
\optdefault{dv}{variable}
is optional, default is DV. If a synonym for DV is set in \$INPUT, the synonym must be set as the dependent variable on the commandline, -dv=$<$synonym$>$. 
\nextopt
\optname{keep\_estimation}
is optional, by default not set. If this option is set, a post-hoc evaluation step is performed for each simulated dataset (\$ESTIMATION is kept and MAXEVALS is set to 0). Note that in this case variables such as IPRED(F) are based on the re-estimated post-hoc parameters. Also note that in earlier program versions keep\_estimation was set or unset automatically, see section Additional rules and logic 3). 
\nextopt
\optname{noprediction}
is optional, by default not set. If set, NOPREDICTION will be added to the \$SIMULATION record of the simulation model, in addition to ONLYSIMULATION. This option is generally recommended with likelihood models for odd type data (i.e. -2LOGLIKELIHOOD or LIKELIHOOD in \$ESTIMATION). It is not allowed to use -noprediction in combination with the option \mbox{-keep\_estimation}. 
\nextopt
\optdefault{censor}{variable}
is optional, default not used. Name of variable which defines whether the observation of the dependent variable is missing, e.g. due to drop-out. 1 means the observation is censored, 0 means the observation is not censored. The variable must be requestable in \$TABLE. This option is not applicable for time-to-event data, please read the section 'VPC for time-to-event models'. 
\nextopt
\optdefault{idv}{variable}
optional, default TIME, the independent variable. 
\nextopt
\optdefault{lloq}{number}
optional, the lower limit of quantification for left censored data. Specific for VPC. 
\nextopt
\optdefault{uloq}{number}
optional, the upper limit of quantification for right censored data. Specific for VPC. 
\nextopt
\optdefault{rawres\_input}{filename}
A simple way to simulate with uncertainty. Instead of using identical parameter estimates for simulation of each new dataset, take parameter estimates from a raw\_results.csv file, e.g. from a bootstrap run or the intial\_estimates.csv file from a previous sse run with \$PRIOR in the simulation model. The raw results file must be comma-separated and contain at least as many samples as the input -samples to sse, the labels for THETA/OMEGA/SIGMA in the file must match the labels in the simulation model given as input to sse, the theta columns must be directly followed by the omega columns which must be directly followed by the sigma columns, and the column header must be model either in the first column just as in a bootstrap raw\_results file or in the second or third column as in a sse raw\_results file. If a column header contains a comma, e.g. OMEGA(2,2), then that header must be enclosed in double quotes. This is done automatically in PsN raw results files. Note that is is possible to generate a file with initial parameter estimates outside of PsN, as long as the file follows the format rules. 
\nextopt
\optdefault{offset\_rawres}{N}
Only relevant in combination with -rawres\_input. Default 1. The number of result lines to skip in the input raw results file before starting to read final parameter estimates. In a regular bootstrap raw\_results file the first line of estimates refers to the input model with the full dataset, so therefore the default offset is 1. 
\nextopt
\optname{nca\_options}
This option takes a string that will be copied verbatim to the R script created to invoke nca.R. Strings containing spaces or double quotes can be enclosed within single quotes. Example: \verb|nca run1.mod -nca_options='blq = "yes", blqNm = "BLQ"'|
\nextopt
\end{optionlist}



\subsection{Simulation input details}
The option -samples is required. The scripts does not allow -samples to be smaller than 20, but in order for the analysis to produce meaningful results samples needs to be much larger. No model estimation is performed for the simulated datasets, except for a post-hoc estimation step in case -keep\_estimation is set (then MAXEVALS=0 in \$ESTIMATION). There are five ways of choosing which parameter values are to be used in the simulations: 

\begin{enumerate}
	\item Default: the initial estimates from the lst-file with the same name as the modelfile but with .mod replaced with .lst, e.g. run123.lst if the modelfile is run123.mod. If no such lst-file exists the estimates from the modelfile are used.
	\item the final estimates from a lst-file whose name is not the modelfile name with .mod replaced with .lst: use command-line option -lst=$\langle$filename$\rangle$
	\item the final estimates from an msfo-file: use command-line option -msfo=$<$filename$>$
	\item final estimates from a raw\_results file, e.g. from a bootstrap. This method implies using a different set of estimates for each sample. 
	\item parameter estimates drawn from a prior distribution defined using \$PRIOR in the input/simulation model.
\end{enumerate}

Alternatives 4) and 5) result in simulation with uncertainty. Note that this is normally not appropriate for a vpc or npc. 

The user may either skip the \$SIMULATION record entirely and let the program produce it according to the rules specified in section Modified models â€“ model for simulated data. Or the user can include a complete \$SIMULATION record, for example when using special random distributions. Inclusion of a \$SIMULATION record is needed when simulating categorical data is intended (vpc with -levels option). In this case the model file must be equipped with IF(ICALL.EQ.4) coding to separate the simulation model from the estimation model, and the \$SIMULATION record must contain both a normal seed and a uniform seed (1234 UNIFORM). If there is a user-defined \$SIMULATION record, the program will replace the random seeds, set NSUBPROBLEMS to the number of samples requested on the input line, check that TRUE=FINAL is set in the case when the option -msfo is used, and set/unset ONLYSIMULATION to be compatible with the option keep\_estimation. If option rawres\_input is used, the program will create one simulation model per sample.

An additional alternative is to supply the program with a complete simulation model, either via option -flip\_comments or option -sim\_model. In both cases the program will only change seeds and NSUBPROBLEMS in \$SIMULATION. No other changes to that particular record will be made.

\subsection{Handling BQL data}
It is important to retain the BQL observation in the data-set when doing VPCs (see Bergstrand, M. et al. AAPS J, 2009. 11(2): p. 371-380. for more details). It should be done irrespectively of what method that is used to handle or not handle the BQL observations when estimating. The M3/M4 code used to include BQL samples in the estimation is only applicable to estimation and not to simulation. With the M3/M4 code the BQL observations are treated as categorical observations (i.e. $<$LOQ). When you simulate you want to generate simulated concentration observations at all time points in your data-set (also where the observations was $<$LOQ). If you simulate with the M3/M4 code active the prediction at BQL samples in your data-set (F\_FLAG=1) will be the probability for the observation to be <LOQ and not a concentration. For this reason PsN highlights that if F\_FLAG is used there needs to be a special simulation block (ICALL.EQ.4) where the prediction is coded to be continuous (F\_FLAG=0) for all observations. In theory it should be possible to have the M3/M4 cod in a block that only applies to estimation but NONMEM often gives error messages when this is tried. For that reason it is recommended to construct a new control stream for the VPC (e.g. run1vpc.mod). In the new model file remove code that relates to the M3/M4 method so that continuous predictions are given at all observations. It is important that the DV value for all BQL observations are set to a value below LOQ (e.g. LOQ/2) in the data-set. 

\subsection{Simulation with uncertainty}
It is possible to simulate with uncertainty in npc/vpc, either by using option -rawres\_input or by having \$PRIOR in the input/simulation model.

\subsection{Dependent variable option, -dv}
The default dependent variable to do the analysis on is DV. Other possible choices are IPRED, IRES, IWRES, IPRED, RES, WRES or any other variable defined in the \$PRED/\$ERROR/\$PK record in the modelfile. Defining a new variable allows the user to, for example, perform any sort of transformation of the observations. CWRES may also be chosen, but Xpose (a post-processing program in R) may not be able to handle large tablefiles and tablefiles lacking a run number. 

\subsection{Common options in PsN which are interesting for NCA (examples)}
For a complete list of common options see common\_options\_defaults\_versions.pdf, or psn\_options -h on the commandline.

\begin{optionlist}
\nextopt
\optname{last\_est\_complete}
optional and only applies with NONMEM7 and if option -keep\_estimation is set. See section NPC and VPC with NONMEM7. 
\nextopt
\optdefault{seed}{string}
Using this option makes it possible to regenerate simulation results. 
\nextopt
\optdefault{directory}{directory name}
name of new directory or directory to restart from 
\nextopt
\optdefault{nm\_version}{nonmem version }

\nextopt
\end{optionlist}

Important note: you can use the -directory option e.g when you have run a simulation with a particular model earlier and you want to stratify on a new column or use a different set of binning options. You can reuse NPC simulations in a VPC analysis and vice versa, since the underlying program is essentially the same. The default directory name will be of the form npc\_dirN, regardless of whether the original run was done using NPC or VPC. This will save time since much of the processing won't have to be redone. The old npc\_results.csv or vpc\_results.csv file will be renamed so that they are not overwritten.

\section{Output}

\section{General process}
The script checks the input, see section Input checks. Then two modified modelfiles are created, one for generating original data table output and one for generating simulated data table output. The model parameters will never be reestimated. Unless an lst- or msfo-file is given as input or an lst-file is found by replacing .mod with .lst in the modelfile name, the initial parameter estimates from the modelfile will be used for the simulations. The two modified models are run using PsN, and the output in the tablefiles are processed and analyzed according to sections Table output processing and DV matrix analysis for NPC/VPC below. 

\section{Modified models}

\section{Table output processing}
The dependent variable values in observation rows are extracted from original data and simulation table files. The values are saved to disc as a matrix in csv-format. One row per observation, original dataset in the first column and simulated datasets in columns 2-(n\_samples+1). The values saved to disk are never prediction or variability corrected.

If option -censor is used, censor variable values in observation rows are extracted from original data and simulation table files. The values are saved to disc as a matrix in csv-format. One row per observation, original dataset in the first column and simulated datasets in columns 2-(n\_samples+1).

\section{Censoring of data}
If option -censor is used, the missing observations are removed. If option -predcorr is used in combination with option -lloq or -uloq, the observations outside the boundaries of -lloq and -uloq are also removed.

\end{document}
