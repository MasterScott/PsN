\documentclass{article}

\title{Influential individuals without full CDD}
\date{2016-10-31}

\usepackage{hyperref}

\begin{document}

\maketitle

\section*{Monte-Carlo R procedure for uncertainty in ETAs}
\subsection*{Input} phi-file from estimation of original model on full data.
\subsection*{Procedure}
\begin{enumerate}
\item Read phi-file: For each ID (row) $i$
\begin{enumerate}
\item Store ETA(1), ETA(2),... as a vector $\mu_{i}$ of length $N_{eta}$.
\item Reformat ETC column values to a symmetric covariance matrix $Cov_i$. 
\end{enumerate}
\item For $j=1\ldots M$ (suitable value of $M$ needs to be investigated), generate vector $EBE_{mean,j}$
  and matrix $EBE_{cov,j}$ using the following steps
\begin{enumerate}
\item For each individual $i$, draw a single random sample, a vector $EBE_{i,j}$ of length $N_{eta}$,
  from a multivariate normal distribution with mean $\mu_{i}$
  and covariance matrix $Cov_i$.
\item Store the vectors $EBE_{i,j}$ in a matrix $A_j$, with $N_{eta}$ columns and number of
  rows equal to number of individuals, where row $i$ of $A_j$ is vector $EBE_{i,j}$. 
\item Compute $EBE_{mean,j}$ as the mean of all vectors $EBE_{i,j}$, i.e. the mean of each column in $A_{j}$
\item Compute matrix $EBE_{cov,j}$, i.e. the covariance between columns of $A_{j}$. An efficient
  algorithm for this is to subtract $EBE_{mean,j}$ from each row of $A_{j}$ and then perform a QR
  factorization of the new matrix. The triangular matrix $R_j$, dimension $N_{eta}$, is the Cholesky factor
  of $EBE_{cov,j}$, i.e. $R_j^TR_j=EBE_{cov,j}$
\end{enumerate}
\item Compute $EBE_{mean,observed}$ and $EBE_{cov,observed}$ based on the original model phi-file
  ($\mu_{i}$ is row $i$ of $A_{observed}$). 
\item Compute the uncertainty around $EBE_{mean,observed}$ and $EBE_{cov,observed}$ using the $M$ realizations
  of $EBE_{mean,j}$ and $EBE_{cov,j}$: Reformat $EBE_{mean,j}$ and the lower triangle $EBE_{cov,j}$ to a vector,
  create a matrix $B_{original}$ where row $j$ is the vectorized $EBE_{mean,j}$ plus $EBE_{cov,j}$,
  and compute the covariance matrix of $B_{original}$.
  The covariance matrix of $B_{original}$ would be the ``observed''
  data covariance matrix used in Cook score and covariance ratio computations for this simplified
  ``cdd'' procedure. The original data ``parameter vector'' needed for Cook scores would be (????)
  the vectorized $EBE_{mean,observed}$ plus lower triangle $EBE_{cov,observed}$
\item Repeat complete above procedure $N_{individuals}$ times, each time with ID
  $k$, $k=1,\ldots,N_{individuals}$, excluded (like in a CDD).
  The covariance matrix of the case-deleted $B_k$ matrices are used in Cook score and covariance
  ratio computations. The ``parameter vector'' for each case-deleted data set would be (????)
  the vectorized $EBE_{mean,observed,ID\neq k}$ plus lower triangle $EBE_{cov,observed,ID\neq k}$
\end{enumerate}

\section*{Auto-generate NONMEM model for uncertainty in ETAs}
\subsection*{Input} Name of phi-file
\subsection*{Procedure}
\begin{enumerate}
\item Check phi-file exists (use perl command -e)
\item Read phi-file using nmtablefile module, see example in tool/frem.pm , sub get\_correlation\_matrix\_from\_phi
\item write sub for Count ETAs in phi header 
  \item sub compute mean for each ETA column (already have table function get\_column, see example in table.t. Have function for computing mean, see array.t)
  \item compute covariance matrix for ETAs( see example in tool/frem.pm , sub get\_correlation\_matrix\_from\_phi)
  \item sub for generating PRED, input ETA count, output a pred record object (example for creating record of PK type in code\_record.t, PRED type is very similar)
    alternative ??? model::problem::pred->new(record\_arr => ['TVCL=THETA(1)']);
  \item sub for generating THETAs, input list of ETA means from above, output list of theta records (examples generating theta records in theta.t)
  \item sub for generating OMEGA, input is probably covariance matrix from above
  \item sub for generating SIGMA, input ETA count
  \item sub for generating data file, go from the phi-file to the data set::
    \begin{enumerate}
      \item Each ID will have as many lines as ETAs.
       \item In line 1 for an ID, DV is ETA(1) from phi, line 2 will be ETA(2), etc.
         \item  The EBE column will be “1” for ETA1, “2” for ETA2 etc
           \item L2 data item can be the same as ID column
            \item      ETC(1,1),  ETC(2,1)... can be replicated for each line of an ID.
              \item    OBJ isn’t used
      \end{enumerate}
\end{enumerate}
\newpage
\begin{verbatim}
$PROBLEM    Uncertainty in ETAs
$INPUT      ID DV EBE L2 VAR11 COV21 VAR22
$DATA      ebe1.csv IGNORE=@ IGNORE=(ID.GT.100)
$PRED  
IF(EBE.EQ.1) Y=THETA(1)+ETA(1)+EPS(1)*SQRT(VAR11)
IF(EBE.EQ.2) Y=THETA(2)+ETA(2)+EPS(2)*SQRT(VAR22)
$THETA  0.0228385 ; mean of EBE1
$THETA  0.163401 ; mean of EBE2
$OMEGA  BLOCK(2)
 0.0205152  ; 1 var_EBE1
 0.0143489  ;    2 COV21
 0.0492468  ; 3 var_EBE2
$SIGMA  BLOCK(2) FIX
 1
 .01 1  ; as an approximation the same correlation is assumed for all IDs uncertainty.
$ESTIMATION METHOD=1 MAXEVAL=9999 PRINT=1
$COVARIANCE UNCONDITIONAL
$TABLE      ID VAR11 COV12 VAR22 ETA1 ETA2 EBE NOPRINT ONEHEADER
            FILE=mytab2
\end{verbatim}

\begin{verbatim}
ID	DV	         EBE	L2	ETC11	        ETC21	        ETC22
1	-0.1371371192	1	1	0.0989143013	0.0010081493	0.1005629807
1	 0.6035435921	2	1	0.0989143013	0.0010081493	0.1005629807
2	-0.1910422646	1	2	0.0993396641	0.0009540865	0.1003940703
2	 0.2403879379	2	2	0.0993396641	0.0009540865	0.1003940703
\end{verbatim}



\end{document}
